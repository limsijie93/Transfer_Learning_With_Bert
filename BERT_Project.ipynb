{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Project.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "4-3Ju5c2PI8d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning Using BERT \n",
        "\n",
        "## Project Summary: \n",
        "This project aims to use the Google released Bert model for transfer learning. The idea is similar to transfer learning using image recognition model (e.g. VGG, ResNet) by adding a classifer head to the underlying outputs from the base model.\n",
        "\n",
        "### Problem Statement:\n",
        "How can we use transfer learning for an NLP problem to improve classification results? \n",
        "\n",
        "In particular, I am going to tackle the 'Quora Insincere Question Classification' problem on Kaggle.\n",
        "\n",
        "Link: https://www.kaggle.com/c/quora-insincere-questions-classification\n",
        "\n",
        "#### Dataset used:\n",
        "Kaggle competition dataset - Quora Insincere Question Classification\n",
        "\n",
        "#### Resources used:\n",
        "Colab\n",
        "\n",
        "#### Code implemented in:\n",
        "PyTorch\n",
        "\n",
        "#### Credit: Lim Si Jie"
      ]
    },
    {
      "metadata": {
        "id": "RhBc17CuULmV",
        "colab_type": "code",
        "outputId": "be8d5a65-aea0-4b2c-b9a8-8ddab8fc9e44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "!pip install \n",
        "!pip install kaggle --u"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl (114kB)\n",
            "\r\u001b[K    8% |██▉                             | 10kB 15.1MB/s eta 0:00:01\r\u001b[K    17% |█████▊                          | 20kB 4.8MB/s eta 0:00:01\r\u001b[K    26% |████████▋                       | 30kB 6.8MB/s eta 0:00:01\r\u001b[K    35% |███████████▌                    | 40kB 4.4MB/s eta 0:00:01\r\u001b[K    44% |██████████████▍                 | 51kB 5.4MB/s eta 0:00:01\r\u001b[K    53% |█████████████████▏              | 61kB 6.3MB/s eta 0:00:01\r\u001b[K    62% |████████████████████            | 71kB 7.1MB/s eta 0:00:01\r\u001b[K    71% |███████████████████████         | 81kB 7.9MB/s eta 0:00:01\r\u001b[K    80% |█████████████████████████▉      | 92kB 8.7MB/s eta 0:00:01\r\u001b[K    89% |████████████████████████████▊   | 102kB 7.2MB/s eta 0:00:01\r\u001b[K    98% |███████████████████████████████▌| 112kB 7.4MB/s eta 0:00:01\r\u001b[K    100% |████████████████████████████████| 122kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.18.4)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.0.1.post2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.14.6)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.9.123)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2018.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.3.9)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.123 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.12.123)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.123->boto3->pytorch-pretrained-bert) (2.5.3)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.123->boto3->pytorch-pretrained-bert) (0.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.123->boto3->pytorch-pretrained-bert) (1.11.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.1\n",
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n",
            "\n",
            "Usage:   \n",
            "  pip3 install [options] <requirement specifier> [package-index-options] ...\n",
            "  pip3 install [options] -r <requirements file> [package-index-options] ...\n",
            "  pip3 install [options] [-e] <vcs project url> ...\n",
            "  pip3 install [options] [-e] <local project path> ...\n",
            "  pip3 install [options] <archive url/path> ...\n",
            "\n",
            "ambiguous option: --u (--upgrade, --upgrade-strategy, --use-pep517, --user?)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OuOiIrMPZFF1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive to Google's Linux VM (Colab)"
      ]
    },
    {
      "metadata": {
        "id": "YlgNAF-_ZJBK",
        "colab_type": "code",
        "outputId": "2c0a0752-ba55-43c6-845f-d2189980e4d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NVNWpfSaZNeQ",
        "colab_type": "code",
        "outputId": "a904557e-4e99-472b-9d7f-96bee6c3eee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Check whether Google Drive is connected\n",
        "\n",
        "with open('/gdrive/My Drive/test.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat '/gdrive/My Drive/test.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Vswl4a7qZRPD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Connecting to Kaggle API via token and showing all available dataset\n",
        "\n",
        "#Note: Yout can view how to download Kaggle API token here - https://github.com/Kaggle/kaggle-api\n",
        "\n",
        "!pip install -U -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "!cp \"/gdrive/My Drive/Deep Learning Workshop/kaggle.json\" ~/.kaggle/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ieFbRWIi6B_v",
        "colab_type": "code",
        "outputId": "40ae7f77-f48b-44e5-fe32-5932844eb0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "#Test that the kaggle command is working\n",
        "!kaggle datasets list"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ref                                                          title                                                size  lastUpdated          downloadCount  \n",
            "-----------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  \n",
            "ronitf/heart-disease-uci                                     Heart Disease UCI                                     3KB  2018-06-25 11:33:56          23388  \n",
            "russellyates88/suicide-rates-overview-1985-to-2016           Suicide Rates Overview 1985 to 2016                 396KB  2018-12-01 19:18:25          17445  \n",
            "karangadiya/fifa19                                           FIFA 19 complete player dataset                       2MB  2018-12-21 03:52:59          19021  \n",
            "iarunava/cell-images-for-detecting-malaria                   Malaria Cell Images Dataset                         337MB  2018-12-05 05:40:21           3664  \n",
            "lava18/google-play-store-apps                                Google Play Store Apps                                2MB  2019-02-03 13:55:47          46554  \n",
            "jessicali9530/stanford-dogs-dataset                          Stanford Dogs Dataset                               735MB  2019-02-13 05:45:25           2047  \n",
            "bigquery/crypto-ethereum-classic                             Ethereum Classic Blockchain                          70GB  2019-03-20 23:21:25              0  \n",
            "vjchoudhary7/customer-segmentation-tutorial-in-python        Mall Customer Segmentation Data                       2KB  2018-08-11 07:23:02           5935  \n",
            "noriuk/us-education-datasets-unification-project             U.S. Education Datasets: Unification Project         85MB  2019-03-02 18:41:52           2777  \n",
            "mdhrumil/top-5000-youtube-channels-data-from-socialblade     Top 5000 Youtube channels data from Socialblade.    128KB  2018-09-09 14:05:54           6872  \n",
            "jessicali9530/celeba-dataset                                 CelebFaces Attributes (CelebA) Dataset                1GB  2018-06-01 20:08:48           5913  \n",
            "cityofLA/los-angeles-parking-citations                       Los Angeles Parking Citations                       256MB  2019-04-02 22:18:15           2744  \n",
            "safegraph/visit-patterns-by-census-block-group               Consumer & Visitor Insights For Neighborhoods        66MB  2018-12-19 21:31:50           1155  \n",
            "safegraph/census-block-group-american-community-survey-data  Census Block Group American Community Survey Data     2GB  2018-12-22 00:29:56            616  \n",
            "pavansanagapati/urban-sound-classification                   Urban Sound Classification                            6GB  2018-06-16 13:44:36           2055  \n",
            "anokas/kuzushiji                                             Kuzushiji-MNIST                                     318MB  2018-12-17 01:19:31            713  \n",
            "jutrera/stanford-car-dataset-by-classes-folder               Stanford Car Dataset by classes folder                2GB  2018-07-02 07:35:45           2530  \n",
            "fivethirtyeight/fivethirtyeight-comic-characters-dataset     FiveThirtyEight Comic Characters Dataset            577KB  2019-03-26 15:01:15           1967  \n",
            "mohansacharya/graduate-admissions                            Graduate Admissions                                   9KB  2018-12-28 10:07:14          16496  \n",
            "rmisra/news-headlines-dataset-for-sarcasm-detection          News Headlines Dataset For Sarcasm Detection          2MB  2018-06-09 22:14:56           2251  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "v8BpOqle6Oej",
        "colab_type": "code",
        "outputId": "6b5d2012-5e62-438b-f6a5-feccc3816011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "#Download the Kaggle NLP dataset that you are interested in\n",
        "#In my case, I am downloading the quora insincere question classification dataset\n",
        "\n",
        "!kaggle competitions download -c quora-insincere-questions-classification"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading train.csv.zip to /content\n",
            " 75% 41.0M/54.4M [00:00<00:00, 24.1MB/s]\n",
            "100% 54.4M/54.4M [00:01<00:00, 50.9MB/s]\n",
            "Downloading embeddings.zip to /content\n",
            "100% 5.95G/5.96G [01:39<00:00, 84.1MB/s]\n",
            "100% 5.96G/5.96G [01:40<00:00, 63.9MB/s]\n",
            "Downloading sample_submission.csv.zip to /content\n",
            "100% 4.08M/4.08M [00:00<00:00, 16.0MB/s]\n",
            "\n",
            "Downloading test.csv.zip to /content\n",
            " 70% 11.0M/15.7M [00:00<00:00, 13.8MB/s]\n",
            "100% 15.7M/15.7M [00:00<00:00, 21.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GW-aVmzb7shC",
        "colab_type": "code",
        "outputId": "25ced71b-a3cb-4080-e015-5d6a9723fcbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -al\n",
        "\n",
        "#!unzip embeddings.zip (I'm not unzipping the embeddings since I won't be using it in my approach)\n",
        "!unzip train.csv.zip\n",
        "!unzip test.csv.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 6321976\n",
            "drwxr-xr-x 1 root root       4096 Apr  3 12:32 .\n",
            "drwxr-xr-x 1 root root       4096 Apr  3 12:26 ..\n",
            "drwxr-xr-x 1 root root       4096 Mar 27 20:25 .config\n",
            "-rw-r--r-- 1 root root 6395920052 Apr  3 12:31 embeddings.zip\n",
            "drwxr-xr-x 1 root root       4096 Mar 27 20:26 sample_data\n",
            "-rw-r--r-- 1 root root    4282631 Apr  3 12:32 sample_submission.csv.zip\n",
            "-rw-r--r-- 1 root root   16426497 Apr  3 12:32 test.csv.zip\n",
            "-rw-r--r-- 1 root root   57047694 Apr  3 12:30 train.csv.zip\n",
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n",
            "Archive:  test.csv.zip\n",
            "  inflating: test.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "szAzitP7i-Yl",
        "colab_type": "code",
        "outputId": "b17e9d22-d92c-4424-9232-30f09b984e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -al"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 6477464\n",
            "drwxr-xr-x 1 root root       4096 Apr  3 12:32 .\n",
            "drwxr-xr-x 1 root root       4096 Apr  3 12:26 ..\n",
            "drwxr-xr-x 1 root root       4096 Mar 27 20:25 .config\n",
            "-rw-r--r-- 1 root root 6395920052 Apr  3 12:31 embeddings.zip\n",
            "drwxr-xr-x 1 root root       4096 Mar 27 20:26 sample_data\n",
            "-rw-r--r-- 1 root root    4282631 Apr  3 12:32 sample_submission.csv.zip\n",
            "---------- 1 root root   35011536 Feb  6 00:46 test.csv\n",
            "-rw-r--r-- 1 root root   16426497 Apr  3 12:32 test.csv.zip\n",
            "---------- 1 root root  124206772 Oct 30 16:56 train.csv\n",
            "-rw-r--r-- 1 root root   57047694 Apr  3 12:30 train.csv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fRAG9nu5jTYh",
        "colab_type": "code",
        "outputId": "c0669b00-cdc4-4f6d-c02e-4c270761496b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#Import relevant libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForNextSentencePrediction, BertAdam\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from collections import Counter\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm._tqdm_notebook import tqdm_notebook\n",
        "from tqdm import tqdm\n",
        "\n",
        "tqdm_notebook.pandas(desc='Progress')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5VK_ePvJZgIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing for CUDA"
      ]
    },
    {
      "metadata": {
        "id": "fUKsz97vZfMJ",
        "colab_type": "code",
        "outputId": "19f8d758-1c89-4d0b-846e-4dc575e791a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ytGE2n7ejMqT",
        "colab_type": "code",
        "outputId": "e3c003e5-b146-4202-f4ae-e511e8f46eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Since there are a lot of data in the dataset, I will be subsetting it for debugging/testing of the model first. Else, it will take a long time for my model to train\n",
        "#REMOVE: can remove this line of code when done testing\n",
        "\n",
        "raw_df = pd.read_csv('train.csv')\n",
        "print(len(raw_df[raw_df['target'] == 1]))\n",
        "print(len(raw_df[raw_df['target'] == 0]))\n",
        "\n",
        "pos_df = raw_df[raw_df['target'] == 1].iloc[:100, :]\n",
        "neg_df = raw_df[raw_df['target'] == 0].iloc[:100, :]\n",
        "\n",
        "short_df = pos_df.append(neg_df)\n",
        "\n",
        "short_df.to_csv('train_short.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80810\n",
            "1225312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QsUFpNpiIu72",
        "colab_type": "code",
        "outputId": "027c5f68-ef58-475c-c19b-26ad875602a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "#Activate the logger for more information on what's happening\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpuzydvjcv\n",
            "100%|██████████| 231508/231508 [00:00<00:00, 932836.72B/s]\n",
            "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmpuzydvjcv to cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmpuzydvjcv\n",
            "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y1CttdtHrqfL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Defining the Dataset class to load the NLP dataset\n",
        "\n",
        "class Dataset(Dataset):\n",
        "  'Characterizes a dataset for PyTorch'\n",
        "  def __init__(self, df_path, maxlen):\n",
        "    \n",
        "    'Initialization'\n",
        "    \n",
        "    #This will determine the max length of your tensor. If your tensor length < max length, it will be padded with 0.\n",
        "    #The rational is to have the same tensor length being passed into the model for more efficient computation.\n",
        "    \n",
        "    self.maxlen = maxlen\n",
        "    \n",
        "    #For simplicity, we will remove the indexes where the question is more than 515 in length (Bert has a limit of 515)\n",
        "    self.df = pd.read_csv(df_path).drop(59428, axis = 0).drop(205748, axis = 0).drop(163583, axis = 0).drop(443216, axis = 0) .reset_index()\n",
        "    \n",
        "    \n",
        "    self.df.labels = self.df.target\n",
        "    self.df.text = self.df.question_text\n",
        "    \n",
        "    #Tokenize the questions\n",
        "    \n",
        "    print('Start Tokenizing')\n",
        "    self.df.text = self.df.text.apply(tokenizer.tokenize) #.progress_apply(tokenizer.tokenize)\n",
        "    \n",
        "    #Index the tokens \n",
        "    \n",
        "    print('Start Indexing Tokens')\n",
        "    self.df.text = self.df.text.apply(tokenizer.convert_tokens_to_ids) #progress_apply(tokenizer.convert_tokens_to_ids)\n",
        "    \n",
        "    #Pad the text_index with 0 so that it hits the max_len\n",
        "    \n",
        "    print('Start Padding Process')\n",
        "    self.df.text = self.df.text.apply(self.pad_data) #progress_apply(self.pad_data) \n",
        "    \n",
        "    #Converting all numpy array (for text) to tensor\n",
        "    \n",
        "    print('Converting numpy array to tensor')\n",
        "    self.df.text = self.df.text.apply(torch.from_numpy) #progress_apply(torch.from_numpy)\n",
        "    \n",
        "    #Note: I am overwritting the column to reduce memory usage. If you prefer, you can create new columns for each step (tokenizing, indexing, padding)\n",
        "    \n",
        "    '''print('Start Tokenizing')\n",
        "    self.df.text_token = self.df.text.apply(tokenizer.tokenize) #.progress_apply(tokenizer.tokenize)\n",
        "    \n",
        "    #Index the tokens \n",
        "    \n",
        "    print('Start Indexing Tokens')\n",
        "    self.df.text_idx = self.df.text_token.apply(tokenizer.convert_tokens_to_ids) #progress_apply(tokenizer.convert_tokens_to_ids)\n",
        "    \n",
        "    #Pad the text_index with 0 so that it hits the max_len\n",
        "    \n",
        "    print('Start Padding Process')\n",
        "    self.df.text_idx_padded = self.df.text_idx.apply(self.pad_data) #progress_apply(self.pad_data) \n",
        "    \n",
        "    #Converting all numpy array (for text) to tensor\n",
        "    \n",
        "    print('Converting numpy array to tensor')\n",
        "    self.df.text_idx_padded = self.df.text_idx_padded.apply(torch.from_numpy) #progress_apply(torch.from_numpy)\n",
        "    \n",
        "    #drop the text_token and token_indexing to reduce memory usage\n",
        "    self.df = self.df.drop('text', axis = 1)'''\n",
        "\n",
        "  def __len__(self):\n",
        "    'Denotes the total number of samples'\n",
        "    return len(self.df.text)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    'Generates one sample of data'\n",
        "    # Select sample\n",
        "    text_idx = self.df.text[index]\n",
        "    labels = self.df.labels[index]\n",
        "\n",
        "    return text_idx, labels\n",
        "   \n",
        "  def pad_data(self, s):\n",
        "    #Pad the tensor with zeros so that all tensors have the same length.\n",
        "    padded = np.zeros((self.maxlen,), dtype=np.int64)\n",
        "    if len(s) > self.maxlen: \n",
        "      padded[:] = s[:self.maxlen]\n",
        "    else: padded[:len(s)] = s\n",
        "    return padded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ccSKhhldwqCH",
        "colab_type": "code",
        "outputId": "59bdcb47-4668-46cc-ed1e-429c297da845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "quora_df = Dataset('train.csv', maxlen = 178)\n",
        "\n",
        "#For debugging: \n",
        "#quora_df = Dataset('train_short.csv', maxlen = 178)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Start Tokenizing\n",
            "Start Indexing Tokens\n",
            "Start Padding Process\n",
            "Converting numpy array to tensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vRE2dYbuBw6M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FWclhGkBXfl3",
        "colab_type": "code",
        "outputId": "bd8057be-c19b-4b63-a0a5-5685ea7040a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "#Defining the Bert model \n",
        "\n",
        "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased').to(device) #BertModel\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "  \n",
        "'''model.fc = nn.Sequential(\n",
        "    nn.Linear(178, 2048),\n",
        "    nn.Sigmoid(),\n",
        "    #nn.Dropout(0.1),\n",
        "    nn.Linear(2048, 1024),\n",
        "    nn.Sigmoid(),\n",
        "    #nn.Dropout(0.1),\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.Sigmoid(),\n",
        "    #nn.Dropout(0.1),\n",
        "    nn.Linear(512, 2)).to(device)'''\n",
        "\n",
        "'''model.fc = nn.Sequential(\n",
        "    nn.Embedding(178, 178),\n",
        "    nn.LayerNorm(178, 512),\n",
        "    nn.Hardshrink(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.Hardshrink(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.Hardshrink(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(128, 2)).to(device)'''\n",
        "\n",
        "'''model.fc = nn.Sequential(\n",
        "    nn.BatchNorm1d(178, 178),\n",
        "    nn.Linear(178, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.5),\n",
        "    nn.Linear(256, 2)).to(device)'''\n",
        "\n",
        "'''model.fc = nn.Sequential(\n",
        "    nn.BatchNorm1d(178, 178),\n",
        "    nn.Linear(178, 512),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.Sigmoid(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(256, 2)).to(device)'''\n",
        "\n",
        "'''model.fc = nn.Sequential(\n",
        "    nn.Linear(178, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(256, 2)).to(device)'''\n",
        "\n",
        "'''model.fc = nn.Sequential(\n",
        "    nn.Linear(178, 178),\n",
        "    nn.Hardshrink(),\n",
        "    #nn.Dropout(0.2),\n",
        "    nn.Linear(178, 2)).to(device)'''\n",
        "\n",
        "model.fc = nn.Sequential(\n",
        "    #nn.Embedding(178, 178),\n",
        "    nn.Linear(178, 512),\n",
        "    nn.Hardshrink(),\n",
        "    #nn.Dropout(0.2),\n",
        "    nn.Linear(512, 512),\n",
        "    nn.Hardshrink(),\n",
        "    #nn.Dropout(0.2),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.Hardshrink(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(256, 2)).to(device)\n",
        "\n",
        "class_weight = torch.FloatTensor([1, 17]).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight = class_weight)\n",
        "#criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = BertAdam(model.fc.parameters(), lr = 0.2)\n",
        "\n",
        "#optimizer = BertAdam(model.parameters(), lr = 0.01)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_pretrained_bert.file_utils:https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz not found in cache, downloading to /tmp/tmpaw5td1hx\n",
            "100%|██████████| 407873900/407873900 [00:16<00:00, 25093076.74B/s]\n",
            "INFO:pytorch_pretrained_bert.file_utils:copying /tmp/tmpaw5td1hx to cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.file_utils:creating metadata file for /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.file_utils:removing temp file /tmp/tmpaw5td1hx\n",
            "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
            "INFO:pytorch_pretrained_bert.modeling:extracting archive file /root/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmpcb0zvstt\n",
            "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "8OwjMxBI0TpB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def split_num(dataset, train_split = 0.7):  \n",
        "  dataset_len = len(dataset)  # To check how many elements there are in the dataset\n",
        "  \n",
        "  #train_ and test_ split based on number of elements in the dataset\n",
        "  train_ = round(dataset_len * train_split)\n",
        "  test_ = round(dataset_len * (1 - train_split))\n",
        "  \n",
        "  return (train_, test_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xCuxySRGHJn2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs, file_name):\n",
        "  \n",
        "  max_epochs = num_epochs \n",
        "\n",
        "  min_validation_loss = np.Inf\n",
        "  min_validation_acc = 0\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "\n",
        "      print('Epoch', epoch)\n",
        "      print('-' * 20)\n",
        "      print('')\n",
        "\n",
        "      # Training\n",
        "\n",
        "      model.train() \n",
        "\n",
        "      records = 0\n",
        "      train_running_loss = 0.0\n",
        "      train_running_corrects = 0\n",
        "\n",
        "      for inputs, labels in train_dataloaders:\n",
        "          \n",
        "          if records % 100000 == 0:\n",
        "            print('Training in progress:', '-------->' , records, 'out of', len(train_dataloaders.dataset))\n",
        "          \n",
        "          # Transfer to GPU\n",
        "          inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "          \n",
        "          # forward + backward + optimize\n",
        "          bert_output = model.fc(inputs.float())\n",
        "          #bert_output = model(inputs)\n",
        "          #prob = torch.sigmoid(bert_output)\n",
        "          \n",
        "          loss = criterion(bert_output, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          train_running_loss += loss.item()\n",
        "          #_, preds = torch.max(prob, 1)\n",
        "          _, preds = torch.max(bert_output, 1)\n",
        "          \n",
        "          train_running_corrects += torch.sum(preds == labels.long())\n",
        "\n",
        "          records += train_dataloaders.batch_size\n",
        "\n",
        "      epoch_loss = train_running_loss / records\n",
        "      epoch_acc = train_running_corrects.item() / records\n",
        "\n",
        "      print('Training loss: {:.4f}, Training accuracy: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "      print('')\n",
        "\n",
        "      test_correct = 0\n",
        "      test_total = 0\n",
        "      test_running_loss = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "\n",
        "          model.eval()\n",
        "\n",
        "          for inputs, labels in test_dataloaders:\n",
        "              \n",
        "              if test_total % 100000 == 0:\n",
        "                print('Validation in progress:', '------>', test_total, 'out of', len(test_dataloaders.dataset))\n",
        "              \n",
        "              inputs, labels = inputs.to(device), labels.to(device)\n",
        "              \n",
        "              outputs = model.fc(inputs.float())\n",
        "              #outputs = model.fc(inputs)\n",
        "\n",
        "              loss = criterion(outputs, labels)\n",
        "\n",
        "              _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "              test_running_loss += loss.item()\n",
        "\n",
        "              test_total += labels.size(0)\n",
        "              test_correct += (predicted == labels).sum().item()\n",
        "\n",
        "          val_loss = test_running_loss / test_total\n",
        "          val_acc = test_correct / test_total\n",
        "              \n",
        "      print('Validation loss: {:4f}'.format(val_loss))\n",
        "      print('Validation accuracy: {:4f}'.format(val_acc))\n",
        "      print('')\n",
        "\n",
        "      #if (val_loss < min_validation_loss) & (val_acc > min_validation_acc):\n",
        "      if (val_acc > min_validation_acc):\n",
        "\n",
        "        #Update min_validation_loss and min_validation_acc if both validation accuracy and validation loss improves \n",
        "        #min_validation_loss = val_loss\n",
        "        min_validation_acc = val_acc\n",
        "\n",
        "        #Save the model weights if both validation accuracy and validation loss improves \n",
        "        torch.save(model.state_dict(), file_name)\n",
        "        print('Model validation loss < previous model. Model saved')\n",
        "        print('')\n",
        "        \n",
        "      print('-' * 20)\n",
        "      print('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ErCYCxi0giX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_set, test_set = random_split(quora_df, split_num(quora_df))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dXPNwHewyxmr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Using the image datasets and the trainforms, define the dataloaders\n",
        "train_dataloaders = DataLoader(\n",
        "            train_set,\n",
        "            batch_size=10000,\n",
        "            shuffle=True,\n",
        "            num_workers=4)\n",
        "\n",
        "test_dataloaders = DataLoader(\n",
        "            test_set,\n",
        "            batch_size=10000,\n",
        "            shuffle=True,\n",
        "            num_workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yu5-ZgDd7PvA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_name = '/gdrive/My Drive/Deep Learning Workshop/Advanced NLP Sequencing/Project/Bert_v2.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q1jPDX5KqCNJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Load model checkpoint so that we don't have to re-run the training\n",
        "#model.load_state_dict(torch.load(file_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LGOLTgh1pML1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "file_name = '/gdrive/My Drive/Deep Learning Workshop/Advanced NLP Sequencing/Project/Bert_v2.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g8QE3zKw698g",
        "colab_type": "code",
        "outputId": "655cdb49-8967-4293-9590-c6240e821d8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 19244
        }
      },
      "cell_type": "code",
      "source": [
        "train_model(model, criterion, optimizer, 2000, file_name)\n",
        "\n",
        "#DataLoader affects how much CUDA memory is being used"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 26476824.9417, Training accuracy: 0.5133\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 337508.450445\n",
            "Validation accuracy: 0.710350\n",
            "\n",
            "Model validation loss < previous model. Model saved\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 1\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 879624.1718, Training accuracy: 0.5038\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 138623.504118\n",
            "Validation accuracy: 0.700063\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 2\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 240507.6489, Training accuracy: 0.5135\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 82373.362094\n",
            "Validation accuracy: 0.591946\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 3\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 160359.6889, Training accuracy: 0.5236\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 129359.256218\n",
            "Validation accuracy: 0.583483\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 4\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 94952.4231, Training accuracy: 0.4935\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 47854.848046\n",
            "Validation accuracy: 0.561231\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 5\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 80320.1920, Training accuracy: 0.5097\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 15055.732336\n",
            "Validation accuracy: 0.087792\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 6\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 36741.5812, Training accuracy: 0.5207\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 25477.974637\n",
            "Validation accuracy: 0.914364\n",
            "\n",
            "Model validation loss < previous model. Model saved\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 7\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 42175.1822, Training accuracy: 0.5047\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 47497.110529\n",
            "Validation accuracy: 0.931857\n",
            "\n",
            "Model validation loss < previous model. Model saved\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 8\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 37730.5430, Training accuracy: 0.5152\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 11929.870032\n",
            "Validation accuracy: 0.834333\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 9\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 34767.7707, Training accuracy: 0.4718\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 48043.262455\n",
            "Validation accuracy: 0.936644\n",
            "\n",
            "Model validation loss < previous model. Model saved\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 10\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 9870.1275, Training accuracy: 0.4927\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 18105.253936\n",
            "Validation accuracy: 0.407151\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 11\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 14470.5321, Training accuracy: 0.5179\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 61445.543231\n",
            "Validation accuracy: 0.872921\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 12\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 28267.1609, Training accuracy: 0.5102\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 7893.101596\n",
            "Validation accuracy: 0.166739\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 13\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 16505.0113, Training accuracy: 0.4799\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 17125.307581\n",
            "Validation accuracy: 0.872778\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 14\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 19060.8298, Training accuracy: 0.4898\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 9945.732831\n",
            "Validation accuracy: 0.149953\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 15\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 13609.5975, Training accuracy: 0.4975\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 8301.966838\n",
            "Validation accuracy: 0.467904\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 16\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 19522.7992, Training accuracy: 0.5338\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 9584.388878\n",
            "Validation accuracy: 0.901481\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 17\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 14665.2741, Training accuracy: 0.5272\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 4820.538298\n",
            "Validation accuracy: 0.745342\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 18\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 10782.7171, Training accuracy: 0.4974\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 1841.333572\n",
            "Validation accuracy: 0.247204\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 19\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 11950.6308, Training accuracy: 0.5040\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 19551.515796\n",
            "Validation accuracy: 0.109628\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 20\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 8144.0876, Training accuracy: 0.4742\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 2959.213929\n",
            "Validation accuracy: 0.316585\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 21\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 15145.0267, Training accuracy: 0.5375\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 44347.161310\n",
            "Validation accuracy: 0.933811\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 22\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 18745.5665, Training accuracy: 0.5187\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 6156.677428\n",
            "Validation accuracy: 0.064035\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 23\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 11735.4678, Training accuracy: 0.4943\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 7006.622828\n",
            "Validation accuracy: 0.907206\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 24\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 7555.9351, Training accuracy: 0.5061\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 13359.001478\n",
            "Validation accuracy: 0.061983\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 25\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 10062.5665, Training accuracy: 0.4905\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 10212.902921\n",
            "Validation accuracy: 0.815149\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 26\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 9119.0037, Training accuracy: 0.5094\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 15577.171861\n",
            "Validation accuracy: 0.923345\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 27\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 11973.7361, Training accuracy: 0.4782\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 10181.583656\n",
            "Validation accuracy: 0.102939\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 28\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 22758.1456, Training accuracy: 0.4875\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 18826.794054\n",
            "Validation accuracy: 0.616441\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 29\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 14567.5188, Training accuracy: 0.4804\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 17321.575786\n",
            "Validation accuracy: 0.937805\n",
            "\n",
            "Model validation loss < previous model. Model saved\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 30\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 12686.0869, Training accuracy: 0.5248\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 7841.393423\n",
            "Validation accuracy: 0.834407\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 31\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 10333.4457, Training accuracy: 0.4852\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 828.129005\n",
            "Validation accuracy: 0.522143\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 32\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 9743.1866, Training accuracy: 0.4934\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 5189.839785\n",
            "Validation accuracy: 0.870576\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 33\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 11921.9663, Training accuracy: 0.4929\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 3437.723246\n",
            "Validation accuracy: 0.680256\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 34\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 6249.0898, Training accuracy: 0.4823\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 14577.827361\n",
            "Validation accuracy: 0.644613\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 35\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 15659.3070, Training accuracy: 0.5295\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 5073.660668\n",
            "Validation accuracy: 0.068822\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 36\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 11495.5858, Training accuracy: 0.4896\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 3981.170278\n",
            "Validation accuracy: 0.649090\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 37\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 9196.6476, Training accuracy: 0.5250\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 2041.678548\n",
            "Validation accuracy: 0.818513\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 38\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 9468.9990, Training accuracy: 0.4884\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 9498.351275\n",
            "Validation accuracy: 0.062021\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 39\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 10174.6993, Training accuracy: 0.5156\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 2482.949696\n",
            "Validation accuracy: 0.062003\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 40\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 6767.1289, Training accuracy: 0.5344\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 11661.923126\n",
            "Validation accuracy: 0.883790\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 41\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 23324.0930, Training accuracy: 0.5050\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 19139.612459\n",
            "Validation accuracy: 0.895147\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 42\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 11205.7078, Training accuracy: 0.5048\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 686.502091\n",
            "Validation accuracy: 0.634979\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 43\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 8591.0549, Training accuracy: 0.5113\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 10308.648977\n",
            "Validation accuracy: 0.821205\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 44\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 7399.1660, Training accuracy: 0.5250\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 14613.833415\n",
            "Validation accuracy: 0.240869\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 45\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 10696.3930, Training accuracy: 0.5235\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n",
            "Validation in progress: ------> 200000 out of 391835\n",
            "Validation in progress: ------> 300000 out of 391835\n",
            "Validation loss: 1483.797305\n",
            "Validation accuracy: 0.336093\n",
            "\n",
            "--------------------\n",
            "\n",
            "Epoch 46\n",
            "--------------------\n",
            "\n",
            "Training in progress: --------> 0 out of 914283\n",
            "Training in progress: --------> 100000 out of 914283\n",
            "Training in progress: --------> 200000 out of 914283\n",
            "Training in progress: --------> 300000 out of 914283\n",
            "Training in progress: --------> 400000 out of 914283\n",
            "Training in progress: --------> 500000 out of 914283\n",
            "Training in progress: --------> 600000 out of 914283\n",
            "Training in progress: --------> 700000 out of 914283\n",
            "Training in progress: --------> 800000 out of 914283\n",
            "Training in progress: --------> 900000 out of 914283\n",
            "Training loss: 4192.9153, Training accuracy: 0.5126\n",
            "\n",
            "Validation in progress: ------> 0 out of 391835\n",
            "Validation in progress: ------> 100000 out of 391835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8uhNmhCiOmJJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}